"""
reporter.py â€” HaftalÄ±k Performans Raporu Orchestrator

Bu dosya tÃ¼m parÃ§alarÄ± bir araya getirir:
  1. DataCollector ile veriyi al
  2. Prompt'u oluÅŸtur
  3. LLM'e gÃ¶nder
  4. CevabÄ± Ã¶nbelleÄŸe al (cache) â€” her page refresh'te API'a gitmez
  5. Sonucu dÃ¶ndÃ¼r

Cache stratejisi:
  Rapor bir kez Ã¼retilince aynÄ± gÃ¼n iÃ§inde tekrar API Ã§aÄŸrÄ±sÄ± yapÄ±lmaz.
  "Raporu Yenile" butonuna basÄ±nca cache temizlenir.
"""

import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional

from .data_collector import WeeklyDataCollector
from .llm_client import LLMClient
from .prompts import SYSTEM_PROMPT, build_weekly_report_prompt

logger = logging.getLogger(__name__)

# Cache dizini
CACHE_DIR  = Path(__file__).parent.parent.parent / "data" / "genai_cache"
CACHE_FILE = CACHE_DIR / "weekly_report.json"


class WeeklyReporter:
    """
    HaftalÄ±k performans raporu oluÅŸturucu.
    
    KullanÄ±m:
        reporter = WeeklyReporter(storage)
        result = reporter.generate()
        
        if result["success"]:
            print(result["report"])        # Markdown rapor
            print(result["context"])       # Ham istatistikler  
        else:
            print(result["error"])         # Hata mesajÄ±
    """

    def __init__(self, storage, days: int = 7, llm_provider: Optional[str] = None):
        """
        Args:
            storage: PaperTradeStorage instance
            days: KaÃ§ gÃ¼nlÃ¼k dÃ¶nemi analiz et
            llm_provider: "openai" | "gemini" | None (.env'den okur)
        """
        self.storage  = storage
        self.days     = days
        self.collector = WeeklyDataCollector(storage, days)
        self.client    = LLMClient(provider=llm_provider)
        CACHE_DIR.mkdir(parents=True, exist_ok=True)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ana Metod
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def generate(self, force_refresh: bool = False) -> Dict:
        """
        HaftalÄ±k raporu Ã¼ret veya Ã¶nbellekten dÃ¶ndÃ¼r.
        
        Args:
            force_refresh: True ise Ã¶nbelleÄŸi yok say, yeniden Ã¼ret
        
        Returns:
            {
                "success": bool,
                "report": str,          # Markdown rapor
                "context": dict,        # Ham istatistikler (deterministik)
                "from_cache": bool,
                "generated_at": str,
                "llm_available": bool,
                "error": str,           # sadece success=False'da
            }
        """
        # 1. Deterministik veriyi her zaman topla
        context = self.collector.collect()

        # 2. Ã–nbellekte geÃ§erli rapor var mÄ±?
        if not force_refresh:
            cached = self._load_cache()
            if cached:
                logger.info("Rapor Ã¶nbellekten yÃ¼klendi")
                return {
                    "success": True,
                    "report": cached["report"],
                    "context": context,         # GÃ¼ncel istatistikler
                    "from_cache": True,
                    "generated_at": cached.get("generated_at", "?"),
                    "llm_available": self.client.is_ready(),
                }

        # 3. LLM mÃ¼sait deÄŸilse â†’ sadece istatistik raporu dÃ¶ndÃ¼r
        if not self.client.is_ready():
            logger.info("LLM mÃ¼sait deÄŸil â€” istatistik raporu dÃ¶ndÃ¼rÃ¼lÃ¼yor")
            return {
                "success": True,
                "report": self._build_stats_only_report(context),
                "context": context,
                "from_cache": False,
                "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M"),
                "llm_available": False,
            }

        # 4. LLM raporu Ã¼ret
        try:
            prompt  = build_weekly_report_prompt(context)
            report  = self.client.complete(
                prompt=prompt,
                system_prompt=SYSTEM_PROMPT,
                max_tokens=1500,
                temperature=0.5,
            )

            if not report:
                raise ValueError("LLM boÅŸ cevap dÃ¶ndÃ¼rdÃ¼")

            # Header ekle
            period = context.get("period", {})
            header = (
                f"# ðŸ¤– AI HaftalÄ±k Performans Raporu\n"
                f"*{period.get('start', '?')} â€” {period.get('end', '?')} | "
                f"OluÅŸturuldu: {datetime.now().strftime('%d %b %Y %H:%M')}*\n\n---\n\n"
            )
            full_report = header + report

            # 5. Ã–nbelleÄŸe kaydet
            self._save_cache(full_report, context)

            return {
                "success": True,
                "report": full_report,
                "context": context,
                "from_cache": False,
                "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M"),
                "llm_available": True,
            }

        except Exception as e:
            logger.error(f"Rapor Ã¼retme hatasÄ±: {e}")
            return {
                "success": False,
                "report": None,
                "context": context,
                "from_cache": False,
                "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M"),
                "llm_available": self.client.is_ready(),
                "error": str(e),
            }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # LLM Olmadan Rapor (Fallback)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _build_stats_only_report(self, context: Dict) -> str:
        """
        API key yokken bile gÃ¶sterilecek yapÄ±landÄ±rÄ±lmÄ±ÅŸ istatistik raporu.
        Bu rapor tamamen deterministik â€” LLM kullanmaz.
        """
        period  = context.get("period", {})
        weekly  = context.get("weekly_summary", {})
        by_type = context.get("by_swing_type", {})
        top_win  = context.get("top_win")
        top_loss = context.get("top_loss")

        win_rate = weekly.get("win_rate", 0)
        pf       = weekly.get("profit_factor", 0)

        # Otomatik deÄŸerlendirme
        if win_rate >= 60 and pf >= 1.5:
            verdict = "ðŸŸ¢ **GÃ¼Ã§lÃ¼ hafta.** Sistem beklentilerin Ã¼zerinde performans gÃ¶sterdi."
        elif win_rate >= 50 and pf >= 1.0:
            verdict = "ðŸŸ¡ **Makul hafta.** Sistem kÃ¢rlÄ± Ã§alÄ±ÅŸÄ±yor, iyileÅŸtirme fÄ±rsatÄ± var."
        elif weekly.get("total", 0) == 0:
            verdict = "â„¹ï¸ Bu dÃ¶nemde kapanan trade yok."
        else:
            verdict = "ðŸ”´ **Zor hafta.** Stop yÃ¶netimi ve setup seÃ§imini gÃ¶zden geÃ§ir."

        lines = [
            f"# ðŸ“Š HaftalÄ±k Performans Ã–zeti",
            f"*{period.get('start','?')} â€” {period.get('end','?')}*",
            f"\n> ðŸ’¡ AI analizi iÃ§in `.env` dosyasÄ±na LLM API key ekle.\n",
            f"---",
            f"\n## Genel Tablo\n",
            f"| Metrik | DeÄŸer |",
            f"|--------|-------|",
            f"| Toplam Trade | {weekly.get('total', 0)} |",
            f"| Win Rate | %{win_rate:.1f} ({weekly.get('wins',0)}W / {weekly.get('losses',0)}L) |",
            f"| Toplam P/L | {weekly.get('total_pnl_pct',0):+.2f}% |",
            f"| Ort. P/L/Trade | {weekly.get('avg_pnl_pct',0):+.2f}% |",
            f"| Ort. KazanÃ§ | {weekly.get('avg_win_pct',0):+.2f}% |",
            f"| Ort. KayÄ±p | {weekly.get('avg_loss_pct',0):+.2f}% |",
            f"| Profit Factor | {pf:.2f}x |",
            f"\n{verdict}",
        ]

        if by_type:
            lines.append("\n## Setup Analizi\n")
            lines.append("| Tip | Trade | Win Rate | Ort. P/L |")
            lines.append("|-----|-------|----------|----------|")
            for st in sorted(by_type.keys()):
                d = by_type[st]
                lines.append(f"| {st} | {d['count']} | %{d['win_rate']:.0f} | {d['avg_pnl']:+.2f}% |")

        if top_win:
            lines.append(f"\nðŸ† **En Ä°yi Trade:** {top_win['ticker']} â†’ {top_win['pnl_pct']:+.2f}%")
        if top_loss:
            lines.append(f"ðŸ”´ **En KÃ¶tÃ¼ Trade:** {top_loss['ticker']} â†’ {top_loss['pnl_pct']:+.2f}%")

        return "\n".join(lines)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Cache YÃ¶netimi
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _load_cache(self) -> Optional[Dict]:
        """
        BugÃ¼ne ait Ã¶nbelleÄŸi yÃ¼kle.
        DÃ¼nkÃ¼ veya daha eski Ã¶nbelleÄŸi geÃ§ersiz say.
        """
        if not CACHE_FILE.exists():
            return None
        try:
            with open(CACHE_FILE, encoding="utf-8") as f:
                cached = json.load(f)

            # Tarih kontrolÃ¼: bugÃ¼n Ã¼retilmiÅŸ mi?
            cached_date = cached.get("generated_at", "")[:10]
            today = datetime.now().strftime("%Y-%m-%d")
            if cached_date != today:
                logger.info("Ã–nbellek eski tarihten â€” yeniden Ã¼retilecek")
                return None

            return cached
        except Exception as e:
            logger.warning(f"Ã–nbellek okuma hatasÄ±: {e}")
            return None

    def _save_cache(self, report: str, context: Dict) -> None:
        """Raporu ve baÄŸlamÄ± Ã¶nbelleÄŸe kaydet."""
        try:
            cache_data = {
                "report": report,
                "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M"),
                "period": context.get("period", {}),
                "summary": context.get("weekly_summary", {}),
            }
            with open(CACHE_FILE, "w", encoding="utf-8") as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            logger.info(f"Rapor Ã¶nbelleÄŸe kaydedildi: {CACHE_FILE}")
        except Exception as e:
            logger.warning(f"Ã–nbellek kaydetme hatasÄ±: {e}")

    def clear_cache(self) -> None:
        """Ã–nbelleÄŸi temizle (yenile butonu iÃ§in)."""
        if CACHE_FILE.exists():
            CACHE_FILE.unlink()
            logger.info("Rapor Ã¶nbelleÄŸi temizlendi")
